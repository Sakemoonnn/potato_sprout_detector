{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79df7c03-8b0f-43db-9ace-b1f1755cacac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”Œ æ­£åœ¨è¼‰å…¥æ¨¡å‹...\n",
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n",
      "âœ… æ‰€æœ‰æ¨¡å‹è¼‰å…¥æˆåŠŸï¼\n",
      "ğŸ” æ­£åœ¨å°‹æ‰¾å¯ç”¨çš„æ”å½±æ©Ÿ...\n",
      "  âœ… æ‰¾åˆ°æ”å½±æ©Ÿï¼Œç´¢å¼•ç‚º: 0\n",
      "  âœ… æ‰¾åˆ°æ”å½±æ©Ÿï¼Œç´¢å¼•ç‚º: 1\n",
      "  âœ… æ‰¾åˆ°æ”å½±æ©Ÿï¼Œç´¢å¼•ç‚º: 2\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ‘‰ è«‹å¾å¯ç”¨çš„ç´¢å¼• [0, 1, 2] ä¸­è¼¸å…¥æ‚¨æƒ³ä½¿ç”¨çš„æ”å½±æ©Ÿç·¨è™Ÿ:  0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… æ‚¨å·²é¸æ“‡ä½¿ç”¨æ”å½±æ©Ÿï¼Œç´¢å¼•ç‚º: 0\n",
      "\n",
      "ğŸ“¹ æ”å½±æ©Ÿå·²å•Ÿå‹•ï¼æŒ‰ä¸‹ 'q' éµé€€å‡ºã€‚\n",
      "ğŸ‘‹ ç¨‹å¼å·²çµæŸã€‚\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "# ç§»é™¤ä¸ä½¿ç”¨çš„ import\n",
    "# from tensorflow.keras.applications.resnet_v2 import preprocess_input\n",
    "from roboflow import Roboflow\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "\n",
    "# --- æ­¥é©Ÿä¸€ï¼šåƒæ•¸è¨­å®š ---\n",
    "# å°‡æ‰€æœ‰å¯èª¿æ•´çš„åƒæ•¸é›†ä¸­ç®¡ç†\n",
    "class Config:\n",
    "    ROBOFLOW_API_KEY = \"UCLBeCClmaD7BW6BWuLG\" # å»ºè­°å¾ç’°å¢ƒè®Šæ•¸è®€å–ï¼Œé¿å…é‡‘é‘°å¤–æ´©\n",
    "    PROJECT_ID = \"potato-detection-3et6q\"\n",
    "    MODEL_VERSION = 11\n",
    "    CLASSIFIER_MODEL_PATH = '../best_potato_model.keras'\n",
    "    CLASSIFIER_IMG_SIZE = (224, 224)\n",
    "    # é€éæ‰¹æ¬¡è™•ç†å„ªåŒ–å¾Œï¼Œå¯ä»¥æ›´é »ç¹åœ°é€²è¡Œåµæ¸¬\n",
    "    PROCESS_EVERY_N_FRAMES = 3\n",
    "    # åˆ†é¡æ¨¡å‹çš„é¡åˆ¥åç¨± (å‡è¨­ 0 æ˜¯ 'Not Sprouted', 1 æ˜¯ 'Sprouted')\n",
    "    CLASS_NAMES = [\"Not Sprouted\", \"Sprouted\"]\n",
    "    # é¡è‰²ç®¡ç†\n",
    "    COLORS = {\n",
    "        \"Sprouted\": (0, 0, 255),       # ç´…è‰²\n",
    "        \"Not Sprouted\": (0, 255, 0) # ç¶ è‰²\n",
    "    }\n",
    "\n",
    "# --- æ­¥é©ŸäºŒï¼šæ¨¡å‹è¼‰å…¥èˆ‡æ”å½±æ©Ÿé¸æ“‡ (é‚è¼¯ä¸è®Šï¼Œåƒ…å¾®èª¿) ---\n",
    "\n",
    "def load_models(config):\n",
    "    \"\"\"è¼‰å…¥æ‰€æœ‰æ¨¡å‹\"\"\"\n",
    "    try:\n",
    "        print(\"ğŸ”Œ æ­£åœ¨è¼‰å…¥æ¨¡å‹...\")\n",
    "        rf = Roboflow(api_key=config.ROBOFLOW_API_KEY)\n",
    "        project = rf.workspace().project(config.PROJECT_ID)\n",
    "        detection_model = project.version(config.MODEL_VERSION).model\n",
    "        classifier_model = tf.keras.models.load_model(config.CLASSIFIER_MODEL_PATH)\n",
    "        print(\"âœ… æ‰€æœ‰æ¨¡å‹è¼‰å…¥æˆåŠŸï¼\")\n",
    "        return detection_model, classifier_model\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ æ¨¡å‹è¼‰å…¥å¤±æ•—: {e}\")\n",
    "        return None, None\n",
    "\n",
    "def find_and_select_camera(max_cameras_to_check=5):\n",
    "    \"\"\"åµæ¸¬ä¸¦è®“ä½¿ç”¨è€…é¸æ“‡æ”å½±æ©Ÿ (èˆ‡åŸç‰ˆé‚è¼¯ç›¸åŒ)\"\"\"\n",
    "    # ... æ­¤è™•çœç•¥æ‚¨åŸæœ¬çš„ find_available_cameras å’Œ select_camera å‡½å¼ç¨‹å¼ç¢¼ ...\n",
    "    # ç‚ºäº†ç°¡æ½”ï¼Œç›´æ¥æ•´åˆåœ¨ä¸€èµ·\n",
    "    available_cameras = []\n",
    "    print(\"ğŸ” æ­£åœ¨å°‹æ‰¾å¯ç”¨çš„æ”å½±æ©Ÿ...\")\n",
    "    for i in range(max_cameras_to_check):\n",
    "        cap = cv2.VideoCapture(i, cv2.CAP_DSHOW)\n",
    "        if cap.isOpened():\n",
    "            print(f\"  âœ… æ‰¾åˆ°æ”å½±æ©Ÿï¼Œç´¢å¼•ç‚º: {i}\")\n",
    "            available_cameras.append(i)\n",
    "            cap.release()\n",
    "        else:\n",
    "            break\n",
    "    if not available_cameras:\n",
    "        print(\"âŒ æ‰¾ä¸åˆ°ä»»ä½•æ”å½±æ©Ÿã€‚\")\n",
    "        return None\n",
    "    if len(available_cameras) == 1:\n",
    "        print(f\"âœ… è‡ªå‹•é¸æ“‡å”¯ä¸€çš„æ”å½±æ©Ÿï¼Œç´¢å¼•ç‚º: {available_cameras[0]}\")\n",
    "        return available_cameras[0]\n",
    "    \n",
    "    # é è¦½é‚è¼¯å¯ä¿ç•™æˆ–ç°¡åŒ–\n",
    "    while True:\n",
    "        try:\n",
    "            choice = input(f\"\\nğŸ‘‰ è«‹å¾å¯ç”¨çš„ç´¢å¼• {available_cameras} ä¸­è¼¸å…¥æ‚¨æƒ³ä½¿ç”¨çš„æ”å½±æ©Ÿç·¨è™Ÿ: \")\n",
    "            selected_index = int(choice)\n",
    "            if selected_index in available_cameras:\n",
    "                print(f\"âœ… æ‚¨å·²é¸æ“‡ä½¿ç”¨æ”å½±æ©Ÿï¼Œç´¢å¼•ç‚º: {selected_index}\")\n",
    "                return selected_index\n",
    "            else:\n",
    "                print(f\"âŒ ç„¡æ•ˆçš„é¸æ“‡ã€‚\")\n",
    "        except ValueError:\n",
    "            print(\"âŒ è¼¸å…¥ç„¡æ•ˆï¼Œè«‹è¼¸å…¥ä¸€å€‹æ•¸å­—ã€‚\")\n",
    "\n",
    "# --- æ­¥é©Ÿä¸‰ï¼šå„ªåŒ–å¾Œçš„æ ¸å¿ƒè™•ç†å‡½å¼ ---\n",
    "\n",
    "def process_frame_with_batching(frame, detection_model, classifier_model, config):\n",
    "    \"\"\"\n",
    "    å°å–®ä¸€ç•«é¢é€²è¡Œåµæ¸¬èˆ‡æ‰¹æ¬¡åˆ†é¡ï¼Œå›å‚³ç¹ªåœ–æ‰€éœ€çš„è³‡è¨Šã€‚\n",
    "    \"\"\"\n",
    "    # 1. æº–å‚™åµæ¸¬\n",
    "    original_h, original_w, _ = frame.shape\n",
    "    # Roboflow æ¨¡å‹é€šå¸¸åœ¨ 640x640 è¨“ç·´ï¼Œå¯ç›´æ¥å‚³å…¥åŸå§‹å¹€ï¼Œå®ƒæœƒè‡ªå‹•ç¸®æ”¾\n",
    "    # ç§»é™¤ä¸å¿…è¦çš„ç£ç¢Ÿå¯«å…¥\n",
    "    predictions = detection_model.predict(frame, confidence=40, overlap=30).json()['predictions']\n",
    "    \n",
    "    crops_to_classify = []\n",
    "    original_boxes = []\n",
    "\n",
    "    # 2. è£åˆ‡æ‰€æœ‰åµæ¸¬åˆ°çš„ç‰©ä»¶\n",
    "    for pred in predictions:\n",
    "        center_x, center_y = int(pred['x']), int(pred['y'])\n",
    "        width, height = int(pred['width']), int(pred['height'])\n",
    "        x1 = max(0, int(center_x - width / 2))\n",
    "        y1 = max(0, int(center_y - height / 2))\n",
    "        x2 = min(original_w, int(center_x + width / 2))\n",
    "        y2 = min(original_h, int(center_y + height / 2))\n",
    "        \n",
    "        cropped_potato = frame[y1:y2, x1:x2]\n",
    "        \n",
    "        if cropped_potato.size > 0:\n",
    "            resized_crop = cv2.resize(cropped_potato, config.CLASSIFIER_IMG_SIZE)\n",
    "            rgb_crop = cv2.cvtColor(resized_crop, cv2.COLOR_BGR2RGB)\n",
    "            crops_to_classify.append(rgb_crop)\n",
    "            original_boxes.append((x1, y1, x2, y2))\n",
    "\n",
    "    # 3. [æ•ˆèƒ½å„ªåŒ–] é€²è¡Œæ‰¹æ¬¡åˆ†é¡\n",
    "    render_info = []\n",
    "    if crops_to_classify:\n",
    "        # å°‡åœ–ç‰‡åˆ—è¡¨è½‰æ›æˆä¸€å€‹ (N, H, W, C) çš„æ‰¹æ¬¡\n",
    "        batch_images = np.array(crops_to_classify)\n",
    "        \n",
    "        # ä¸€æ¬¡æ€§é æ¸¬æ‰€æœ‰åœ–ç‰‡\n",
    "        batch_predictions = classifier_model.predict(batch_images, verbose=0)\n",
    "        \n",
    "        for i, score in enumerate(batch_predictions):\n",
    "            prediction_score = score[0]\n",
    "            box = original_boxes[i]\n",
    "            \n",
    "            # æ ¹æ“šåˆ†æ•¸æ±ºå®šæ¨™ç±¤å’Œé¡è‰²\n",
    "            if prediction_score > 0.5:\n",
    "                class_name = config.CLASS_NAMES[1] # Sprouted\n",
    "                label = f\"{class_name}: {prediction_score:.2f}\"\n",
    "            else:\n",
    "                class_name = config.CLASS_NAMES[0] # Not Sprouted\n",
    "                label = f\"{class_name}: {1-prediction_score:.2f}\"\n",
    "            \n",
    "            color = config.COLORS.get(class_name, (255, 255, 255)) # é è¨­ç™½è‰²\n",
    "            render_info.append((box, label, color))\n",
    "            \n",
    "    return render_info\n",
    "\n",
    "# --- æ­¥é©Ÿå››ï¼šä¸»è¿´åœˆ ---\n",
    "\n",
    "def main():\n",
    "    config = Config()\n",
    "    detection_model, classifier_model = load_models(config)\n",
    "    \n",
    "    if not (detection_model and classifier_model):\n",
    "        return\n",
    "\n",
    "    selected_cam_index = find_and_select_camera()\n",
    "    if selected_cam_index is None:\n",
    "        return\n",
    "\n",
    "    cap = cv2.VideoCapture(selected_cam_index, cv2.CAP_DSHOW)\n",
    "    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        print(f\"âŒ éŒ¯èª¤ï¼šç„¡æ³•æ‰“é–‹æ”å½±æ©Ÿ {selected_cam_index}ã€‚\")\n",
    "        return\n",
    "\n",
    "    print(\"\\nğŸ“¹ æ”å½±æ©Ÿå·²å•Ÿå‹•ï¼æŒ‰ä¸‹ 'q' éµé€€å‡ºã€‚\")\n",
    "    \n",
    "    frame_counter = 0\n",
    "    latest_render_info = []\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret: break\n",
    "\n",
    "        if frame_counter % config.PROCESS_EVERY_N_FRAMES == 0:\n",
    "            latest_render_info = process_frame_with_batching(frame, detection_model, classifier_model, config)\n",
    "        \n",
    "        # ä½¿ç”¨æœ€æ–°çš„ç¹ªåœ–è³‡è¨Šä¾†æ›´æ–°ç•«é¢\n",
    "        for box, label, color in latest_render_info:\n",
    "            (x1, y1, x2, y2) = box\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
    "            cv2.putText(frame, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
    "        \n",
    "        cv2.imshow('Real-time Potato Sprout Detection', frame)\n",
    "        \n",
    "        frame_counter += 1\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    # ç¢ºä¿æ‰€æœ‰è¦–çª—éƒ½å·²é—œé–‰\n",
    "    for i in range(5):\n",
    "        cv2.waitKey(1)\n",
    "    print(\"ğŸ‘‹ ç¨‹å¼å·²çµæŸã€‚\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638ba710-39a3-469c-bafe-3ccdde43e70d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
