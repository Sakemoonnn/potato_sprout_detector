#!/usr/bin/env python
# coding: utf-8

# In[2]:


import tensorflow as tf
from tensorflow.keras.applications.resnet_v2 import preprocess_input
from roboflow import Roboflow
import cv2
import numpy as np
import os
import time
import sys

def resource_path(relative_path):
    """ å–å¾—æ‰“åŒ…å¾Œè³‡æºçš„çµ•å°è·¯å¾‘ """
    try:
        # PyInstaller å»ºç«‹ä¸€å€‹æš«å­˜è³‡æ–™å¤¾ä¸¦å°‡è·¯å¾‘å­˜åœ¨ _MEIPASS
        base_path = sys._MEIPASS
    except Exception:
        base_path = os.path.abspath(".")

    return os.path.join(base_path, relative_path)
    
# --- æ­¥é©Ÿä¸€ï¼šå®šç¾©åµæ¸¬å’Œé¸æ“‡æ”å½±æ©Ÿçš„å‡½å¼ ---

def find_available_cameras(max_cameras_to_check=10):
    """
    æ¸¬è©¦ç´¢å¼• 0 åˆ° max_cameras_to_check-1ï¼Œå›å‚³æ‰€æœ‰å¯ç”¨çš„æ”å½±æ©Ÿç´¢å¼•åˆ—è¡¨ã€‚
    """
    available_cameras = []
    print("ğŸ” æ­£åœ¨å°‹æ‰¾å¯ç”¨çš„æ”å½±æ©Ÿ...")
    for i in range(max_cameras_to_check):
        cap = cv2.VideoCapture(i, cv2.CAP_DSHOW)
        if cap.isOpened():
            print(f"  âœ… æ‰¾åˆ°æ”å½±æ©Ÿï¼Œç´¢å¼•ç‚º: {i}")
            available_cameras.append(i)
            cap.release()
        else:
            # åœ¨æ‰¾ä¸åˆ°æ›´å¤šæ”å½±æ©Ÿæ™‚å¯ä»¥ææ—©çµæŸï¼Œä»¥ç¯€çœæ™‚é–“
            break
    return available_cameras

def select_camera(camera_indices):
    """
    æ ¹æ“šæ‰¾åˆ°çš„æ”å½±æ©Ÿç´¢å¼•åˆ—è¡¨ï¼Œè®“ä½¿ç”¨è€…é¸æ“‡ã€‚
    """
    if not camera_indices:
        print("âŒ æ‰¾ä¸åˆ°ä»»ä½•æ”å½±æ©Ÿã€‚")
        return None
    
    if len(camera_indices) == 1:
        print(f"âœ… è‡ªå‹•é¸æ“‡å”¯ä¸€çš„æ”å½±æ©Ÿï¼Œç´¢å¼•ç‚º: {camera_indices[0]}")
        return camera_indices[0]

    print("\nğŸ“· ç™¼ç¾å¤šå€‹æ”å½±æ©Ÿï¼Œå°‡é€ä¸€é¡¯ç¤ºé è¦½ç•«é¢2ç§’é˜...")
    
    for index in camera_indices:
        cap = cv2.VideoCapture(index, cv2.CAP_DSHOW)
        if not cap.isOpened():
            continue
        
        print(f"  é è¦½ä¾†è‡ªæ”å½±æ©Ÿç´¢å¼• {index} (é è¦½è¦–çª—å¯èƒ½æœƒå½ˆå‡ºåœ¨èƒŒæ™¯)...")
        start_time = time.time()
        window_name = f"Preview from Camera Index {index} (Close in 2s)"
        
        while time.time() - start_time < 2:
            ret, frame = cap.read()
            if not ret:
                break
            cv2.putText(frame, f"Index: {index}", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
            cv2.imshow(window_name, frame)
            if cv2.waitKey(1) != -1: # ç­‰å¾…1æ¯«ç§’ï¼Œè®“è¦–çª—å¯ä»¥æ›´æ–°
                break
        
        cap.release()
        cv2.destroyWindow(window_name)

    # è®“ä½¿ç”¨è€…è¼¸å…¥é¸æ“‡
    while True:
        try:
            choice = input(f"\nğŸ‘‰ è«‹å¾å¯ç”¨çš„ç´¢å¼• {camera_indices} ä¸­ï¼Œè¼¸å…¥æ‚¨æƒ³ä½¿ç”¨çš„æ”å½±æ©Ÿç·¨è™Ÿ: ")
            selected_index = int(choice)
            if selected_index in camera_indices:
                print(f"âœ… æ‚¨å·²é¸æ“‡ä½¿ç”¨æ”å½±æ©Ÿï¼Œç´¢å¼•ç‚º: {selected_index}")
                return selected_index
            else:
                print(f"âŒ ç„¡æ•ˆçš„é¸æ“‡ã€‚è«‹è¼¸å…¥ {camera_indices} ä¸­çš„ä¸€å€‹æ•¸å­—ã€‚")
        except ValueError:
            print("âŒ è¼¸å…¥ç„¡æ•ˆï¼Œè«‹è¼¸å…¥ä¸€å€‹æ•¸å­—ã€‚")


# --- æ­¥é©ŸäºŒï¼šä¸»ç¨‹å¼é‚è¼¯ ---

# 1. åƒæ•¸è¨­å®š (èˆ‡ä¹‹å‰ç›¸åŒ)
ROBOFLOW_API_KEY = "UCLBeCClmaD7BW6BWuLG"
PROJECT_ID = "potato-detection-3et6q"
MODEL_VERSION = 11
CLASSIFIER_MODEL_PATH = resource_path('best_potato_model.keras') 
CLASSIFIER_IMG_SIZE = (224, 224)
PROCESS_EVERY_N_FRAMES = 30

# 2. è¼‰å…¥æ¨¡å‹ (èˆ‡ä¹‹å‰ç›¸åŒ)
# ... (æ­¤è™•çœç•¥è¼‰å…¥æ¨¡å‹çš„ç¨‹å¼ç¢¼ï¼Œè«‹ç¢ºä¿å®ƒå€‘å·²æˆåŠŸè¼‰å…¥)
try:
    rf = Roboflow(api_key=ROBOFLOW_API_KEY)
    project = rf.workspace().project(PROJECT_ID)
    detection_model = project.version(MODEL_VERSION).model
    classifier_model = tf.keras.models.load_model(CLASSIFIER_MODEL_PATH)
    print("âœ… æ‰€æœ‰æ¨¡å‹è¼‰å…¥æˆåŠŸï¼")
    print(f"  > åˆ†é¡æ¨¡å‹è·¯å¾‘: {CLASSIFIER_MODEL_PATH}") # å¯ä»¥åŠ ä¸Šé€™è¡Œä¾†åµéŒ¯ï¼Œçœ‹çœ‹è·¯å¾‘æ˜¯å¦æ­£ç¢º
except Exception as e:
    print(f"âŒ æ¨¡å‹è¼‰å…¥å¤±æ•—: {e}")
    detection_model = None
    classifier_model = None
    
# 3. åŸ·è¡Œæ”å½±æ©Ÿé¸æ“‡ä¸¦å•Ÿå‹•ä¸»è¿´åœˆ
if detection_model and classifier_model:
    available_cams = find_available_cameras()
    selected_cam_index = select_camera(available_cams)

    if selected_cam_index is not None:
        cap = cv2.VideoCapture(selected_cam_index, cv2.CAP_DSHOW)
        cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
        if not cap.isOpened():
            print(f"âŒ éŒ¯èª¤ï¼šç„¡æ³•æ‰“é–‹é¸æ“‡çš„æ”å½±æ©Ÿ {selected_cam_index}ã€‚")
        else:
            print("\nğŸ“¹ æ”å½±æ©Ÿå·²å•Ÿå‹•ï¼æŒ‰ä¸‹ 'q' éµé€€å‡ºå¯¦æ™‚åµæ¸¬è¦–çª—ã€‚")
            
            frame_counter = 0
            latest_boxes_and_labels = []

            while True:
                ret, frame = cap.read()
                # print("è®€å–ç•«é¢ä¸­...")
                if not ret: break

                if frame_counter % PROCESS_EVERY_N_FRAMES == 0:
                    latest_boxes_and_labels = []
                    
                    # --- â†“â†“â†“ ä»¥ä¸‹æ˜¯ä¿®æ”¹å¾Œçš„å€å¡Š â†“â†“â†“ ---
                    
                    # 1. ç²å–åŸå§‹ç•«é¢çš„å°ºå¯¸
                    original_h, original_w, _ = frame.shape
                    
                    # 2. å®šç¾©åµæ¸¬ç”¨çš„å°ºå¯¸
                    detection_size = (320, 320)
                    
                    # 3. å°‡ç•«é¢ç¸®æ”¾åˆ°åµæ¸¬ç”¨çš„å°ºå¯¸
                    resized_for_detection = cv2.resize(frame, detection_size)
                    
                    # 4. æš«å­˜ç¸®å°å¾Œçš„åœ–ç‰‡ä¸¦é€²è¡Œåµæ¸¬
                    temp_frame_path = "temp_frame_for_detection.jpg"
                    cv2.imwrite(temp_frame_path, resized_for_detection)
                    predictions = detection_model.predict(temp_frame_path, confidence=40, overlap=30).json()['predictions']
    
                    # 5. è¨ˆç®—å¾ã€Œåµæ¸¬å°ºå¯¸ã€æ”¾å¤§å›ã€ŒåŸå§‹å°ºå¯¸ã€çš„ç¸®æ”¾æ¯”ä¾‹
                    x_scale = original_w / detection_size[0]
                    y_scale = original_h / detection_size[1]
    
                    for pred in predictions:
                        # ç²å–çš„æ˜¯åœ¨ 416x416 åœ–ç‰‡ä¸Šçš„åº§æ¨™
                        center_x, center_y, width, height = int(pred['x']), int(pred['y']), int(pred['width']), int(pred['height'])
                        det_x1, det_y1 = int(center_x - width / 2), int(center_y - height / 2)
                        det_x2, det_y2 = int(center_x + width / 2), int(center_y + height / 2)
    
                        # 6. ï¼ï¼ï¼é—œéµæ­¥é©Ÿï¼šå°‡åµæ¸¬åˆ°çš„åº§æ¨™ç­‰æ¯”ä¾‹æ”¾å¤§å›åŸå§‹å°ºå¯¸ï¼ï¼ï¼
                        draw_x1 = int(det_x1 * x_scale)
                        draw_y1 = int(det_y1 * y_scale)
                        draw_x2 = int(det_x2 * x_scale)
                        draw_y2 = int(det_y2 * y_scale)
    
                        # 7. ä½¿ç”¨ã€Œæ”¾å¤§å¾Œã€çš„åº§æ¨™ä¾†å¾ã€ŒåŸå§‹ã€ç•«é¢ä¸­è£åˆ‡é¦¬éˆ´è–¯
                        # åŠ ä¸Šé‚Šç•Œä¿è­·
                        draw_x1, draw_y1 = max(0, draw_x1), max(0, draw_y1)
                        draw_x2, draw_y2 = min(original_w, draw_x2), min(original_h, draw_y2)
                        
                        # æ³¨æ„ï¼é€™è£¡æ˜¯å¾ `frame` (åŸå§‹ç•«é¢) ä¸­è£åˆ‡
                        cropped_potato = frame[draw_y1:draw_y2, draw_x1:draw_x2]
                        
                        if cropped_potato.size == 0: continue
    
                        # (å¾ŒçºŒçš„åˆ†é¡é æ¸¬é‚è¼¯ä¸è®Š...)
                        resized_crop = cv2.resize(cropped_potato, CLASSIFIER_IMG_SIZE)
                        rgb_crop = cv2.cvtColor(resized_crop, cv2.COLOR_BGR2RGB)
                        img_array = np.expand_dims(rgb_crop, axis=0)
                        # preprocessed_img = preprocess_input(img_array)
                        prediction_score = classifier_model.predict(img_array, verbose=0)[0][0]
                        
                        if prediction_score > 0.5:
                            label = f"Sprouted: {prediction_score:.2f}"
                            color = (0, 0, 255) # ç´…è‰²
                        else:
                            label = f"Not Sprouted: {1-prediction_score:.2f}"
                            color = (0, 255, 0) # ç¶ è‰²
                        
                        # 8. ä¿å­˜æ”¾å¤§å¾Œçš„åº§æ¨™å’Œæ¨™ç±¤ï¼Œä»¥ä¾›ç¹ªåœ–ä½¿ç”¨
                        latest_boxes_and_labels.append(((draw_x1, draw_y1, draw_x2, draw_y2), label, color))
                        
                for box, label, color in latest_boxes_and_labels:
                    (x1, y1, x2, y2) = box
                    cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)
                    cv2.putText(frame, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)
                
                cv2.imshow('Real-time Potato Sprout Detection', frame)
                
                frame_counter += 1

                if cv2.waitKey(1) & 0xFF == ord('q'):
                    break

            cap.release()
            cv2.destroyAllWindows()
            # åœ¨ Jupyter ä¸­ï¼Œæœ‰æ™‚éœ€è¦æ‰‹å‹•é—œé–‰æ‰€æœ‰è¦–çª—
            for i in range(5):
                cv2.waitKey(1)

# In[ ]:




