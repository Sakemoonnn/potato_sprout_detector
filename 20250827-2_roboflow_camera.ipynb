{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7276aef-48e2-4270-8634-ee04ffc30412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n",
      "âœ… æ‰€æœ‰æ¨¡å‹è¼‰å…¥æˆåŠŸï¼\n",
      "ğŸ” æ­£åœ¨å°‹æ‰¾å¯ç”¨çš„æ”å½±æ©Ÿ...\n",
      "  âœ… æ‰¾åˆ°æ”å½±æ©Ÿï¼Œç´¢å¼•ç‚º: 0\n",
      "  âœ… æ‰¾åˆ°æ”å½±æ©Ÿï¼Œç´¢å¼•ç‚º: 1\n",
      "  âœ… æ‰¾åˆ°æ”å½±æ©Ÿï¼Œç´¢å¼•ç‚º: 2\n",
      "\n",
      "ğŸ“· ç™¼ç¾å¤šå€‹æ”å½±æ©Ÿï¼Œå°‡é€ä¸€é¡¯ç¤ºé è¦½ç•«é¢5ç§’é˜...\n",
      "  é è¦½ä¾†è‡ªæ”å½±æ©Ÿç´¢å¼• 0 (é è¦½è¦–çª—å¯èƒ½æœƒå½ˆå‡ºåœ¨èƒŒæ™¯)...\n",
      "  é è¦½ä¾†è‡ªæ”å½±æ©Ÿç´¢å¼• 1 (é è¦½è¦–çª—å¯èƒ½æœƒå½ˆå‡ºåœ¨èƒŒæ™¯)...\n",
      "  é è¦½ä¾†è‡ªæ”å½±æ©Ÿç´¢å¼• 2 (é è¦½è¦–çª—å¯èƒ½æœƒå½ˆå‡ºåœ¨èƒŒæ™¯)...\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ‘‰ è«‹å¾å¯ç”¨çš„ç´¢å¼• [0, 1, 2] ä¸­ï¼Œè¼¸å…¥æ‚¨æƒ³ä½¿ç”¨çš„æ”å½±æ©Ÿç·¨è™Ÿ:  0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… æ‚¨å·²é¸æ“‡ä½¿ç”¨æ”å½±æ©Ÿï¼Œç´¢å¼•ç‚º: 0\n",
      "\n",
      "ğŸ“¹ æ”å½±æ©Ÿå·²å•Ÿå‹•ï¼æŒ‰ä¸‹ 'q' éµé€€å‡ºå¯¦æ™‚åµæ¸¬è¦–çª—ã€‚\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.resnet_v2 import preprocess_input\n",
    "from roboflow import Roboflow\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "\n",
    "# --- æ­¥é©Ÿä¸€ï¼šå®šç¾©åµæ¸¬å’Œé¸æ“‡æ”å½±æ©Ÿçš„å‡½å¼ ---\n",
    "\n",
    "def find_available_cameras(max_cameras_to_check=10):\n",
    "    \"\"\"\n",
    "    æ¸¬è©¦ç´¢å¼• 0 åˆ° max_cameras_to_check-1ï¼Œå›å‚³æ‰€æœ‰å¯ç”¨çš„æ”å½±æ©Ÿç´¢å¼•åˆ—è¡¨ã€‚\n",
    "    \"\"\"\n",
    "    available_cameras = []\n",
    "    print(\"ğŸ” æ­£åœ¨å°‹æ‰¾å¯ç”¨çš„æ”å½±æ©Ÿ...\")\n",
    "    for i in range(max_cameras_to_check):\n",
    "        cap = cv2.VideoCapture(i, cv2.CAP_DSHOW)\n",
    "        if cap.isOpened():\n",
    "            print(f\"  âœ… æ‰¾åˆ°æ”å½±æ©Ÿï¼Œç´¢å¼•ç‚º: {i}\")\n",
    "            available_cameras.append(i)\n",
    "            cap.release()\n",
    "        else:\n",
    "            # åœ¨æ‰¾ä¸åˆ°æ›´å¤šæ”å½±æ©Ÿæ™‚å¯ä»¥ææ—©çµæŸï¼Œä»¥ç¯€çœæ™‚é–“\n",
    "            break\n",
    "    return available_cameras\n",
    "\n",
    "def select_camera(camera_indices):\n",
    "    \"\"\"\n",
    "    æ ¹æ“šæ‰¾åˆ°çš„æ”å½±æ©Ÿç´¢å¼•åˆ—è¡¨ï¼Œè®“ä½¿ç”¨è€…é¸æ“‡ã€‚\n",
    "    \"\"\"\n",
    "    if not camera_indices:\n",
    "        print(\"âŒ æ‰¾ä¸åˆ°ä»»ä½•æ”å½±æ©Ÿã€‚\")\n",
    "        return None\n",
    "    \n",
    "    if len(camera_indices) == 1:\n",
    "        print(f\"âœ… è‡ªå‹•é¸æ“‡å”¯ä¸€çš„æ”å½±æ©Ÿï¼Œç´¢å¼•ç‚º: {camera_indices[0]}\")\n",
    "        return camera_indices[0]\n",
    "\n",
    "    print(\"\\nğŸ“· ç™¼ç¾å¤šå€‹æ”å½±æ©Ÿï¼Œå°‡é€ä¸€é¡¯ç¤ºé è¦½ç•«é¢5ç§’é˜...\")\n",
    "    \n",
    "    for index in camera_indices:\n",
    "        cap = cv2.VideoCapture(index, cv2.CAP_DSHOW)\n",
    "        if not cap.isOpened():\n",
    "            continue\n",
    "        \n",
    "        print(f\"  é è¦½ä¾†è‡ªæ”å½±æ©Ÿç´¢å¼• {index} (é è¦½è¦–çª—å¯èƒ½æœƒå½ˆå‡ºåœ¨èƒŒæ™¯)...\")\n",
    "        start_time = time.time()\n",
    "        window_name = f\"Preview from Camera Index {index} (Close in 5s)\"\n",
    "        \n",
    "        while time.time() - start_time < 2:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            cv2.putText(frame, f\"Index: {index}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "            cv2.imshow(window_name, frame)\n",
    "            if cv2.waitKey(1) != -1: # ç­‰å¾…1æ¯«ç§’ï¼Œè®“è¦–çª—å¯ä»¥æ›´æ–°\n",
    "                break\n",
    "        \n",
    "        cap.release()\n",
    "        cv2.destroyWindow(window_name)\n",
    "\n",
    "    # è®“ä½¿ç”¨è€…è¼¸å…¥é¸æ“‡\n",
    "    while True:\n",
    "        try:\n",
    "            choice = input(f\"\\nğŸ‘‰ è«‹å¾å¯ç”¨çš„ç´¢å¼• {camera_indices} ä¸­ï¼Œè¼¸å…¥æ‚¨æƒ³ä½¿ç”¨çš„æ”å½±æ©Ÿç·¨è™Ÿ: \")\n",
    "            selected_index = int(choice)\n",
    "            if selected_index in camera_indices:\n",
    "                print(f\"âœ… æ‚¨å·²é¸æ“‡ä½¿ç”¨æ”å½±æ©Ÿï¼Œç´¢å¼•ç‚º: {selected_index}\")\n",
    "                return selected_index\n",
    "            else:\n",
    "                print(f\"âŒ ç„¡æ•ˆçš„é¸æ“‡ã€‚è«‹è¼¸å…¥ {camera_indices} ä¸­çš„ä¸€å€‹æ•¸å­—ã€‚\")\n",
    "        except ValueError:\n",
    "            print(\"âŒ è¼¸å…¥ç„¡æ•ˆï¼Œè«‹è¼¸å…¥ä¸€å€‹æ•¸å­—ã€‚\")\n",
    "\n",
    "\n",
    "# --- æ­¥é©ŸäºŒï¼šä¸»ç¨‹å¼é‚è¼¯ ---\n",
    "\n",
    "# 1. åƒæ•¸è¨­å®š (èˆ‡ä¹‹å‰ç›¸åŒ)\n",
    "ROBOFLOW_API_KEY = \"UCLBeCClmaD7BW6BWuLG\"\n",
    "PROJECT_ID = \"potato-detection-3et6q\"\n",
    "MODEL_VERSION = 11\n",
    "CLASSIFIER_MODEL_PATH = 'best_potato_model.keras'\n",
    "CLASSIFIER_IMG_SIZE = (224, 224)\n",
    "PROCESS_EVERY_N_FRAMES = 15\n",
    "\n",
    "# 2. è¼‰å…¥æ¨¡å‹ (èˆ‡ä¹‹å‰ç›¸åŒ)\n",
    "# ... (æ­¤è™•çœç•¥è¼‰å…¥æ¨¡å‹çš„ç¨‹å¼ç¢¼ï¼Œè«‹ç¢ºä¿å®ƒå€‘å·²æˆåŠŸè¼‰å…¥)\n",
    "try:\n",
    "    rf = Roboflow(api_key=ROBOFLOW_API_KEY)\n",
    "    project = rf.workspace().project(PROJECT_ID)\n",
    "    detection_model = project.version(MODEL_VERSION).model\n",
    "    classifier_model = tf.keras.models.load_model(CLASSIFIER_MODEL_PATH)\n",
    "    print(\"âœ… æ‰€æœ‰æ¨¡å‹è¼‰å…¥æˆåŠŸï¼\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ æ¨¡å‹è¼‰å…¥å¤±æ•—: {e}\")\n",
    "    detection_model = None\n",
    "    classifier_model = None\n",
    "    \n",
    "# 3. åŸ·è¡Œæ”å½±æ©Ÿé¸æ“‡ä¸¦å•Ÿå‹•ä¸»è¿´åœˆ\n",
    "if detection_model and classifier_model:\n",
    "    available_cams = find_available_cameras()\n",
    "    selected_cam_index = select_camera(available_cams)\n",
    "\n",
    "    if selected_cam_index is not None:\n",
    "        cap = cv2.VideoCapture(selected_cam_index, cv2.CAP_DSHOW)\n",
    "        if not cap.isOpened():\n",
    "            print(f\"âŒ éŒ¯èª¤ï¼šç„¡æ³•æ‰“é–‹é¸æ“‡çš„æ”å½±æ©Ÿ {selected_cam_index}ã€‚\")\n",
    "        else:\n",
    "            print(\"\\nğŸ“¹ æ”å½±æ©Ÿå·²å•Ÿå‹•ï¼æŒ‰ä¸‹ 'q' éµé€€å‡ºå¯¦æ™‚åµæ¸¬è¦–çª—ã€‚\")\n",
    "            \n",
    "            frame_counter = 0\n",
    "            latest_boxes_and_labels = []\n",
    "\n",
    "            while True:\n",
    "                ret, frame = cap.read()\n",
    "                if not ret: break\n",
    "\n",
    "                if frame_counter % PROCESS_EVERY_N_FRAMES == 0:\n",
    "                    latest_boxes_and_labels = []\n",
    "                    temp_frame_path = \"temp_frame_for_detection.jpg\"\n",
    "                    cv2.imwrite(temp_frame_path, frame)\n",
    "                    predictions = detection_model.predict(temp_frame_path, confidence=40, overlap=30).json()['predictions']\n",
    "\n",
    "                    for pred in predictions:\n",
    "                        # ... (åµæ¸¬ã€è£åˆ‡ã€åˆ†é¡ã€æ¨™ç±¤çš„é‚è¼¯èˆ‡ä¹‹å‰å®Œå…¨ç›¸åŒ)\n",
    "                        center_x, center_y, width, height = int(pred['x']), int(pred['y']), int(pred['width']), int(pred['height'])\n",
    "                        x1, y1 = int(center_x - width / 2), int(center_y - height / 2)\n",
    "                        x2, y2 = int(center_x + width / 2), int(center_y + height / 2)\n",
    "                        x1, y1, x2, y2 = max(0, x1), max(0, y1), min(frame.shape[1], x2), min(frame.shape[0], y2)\n",
    "                        cropped_potato = frame[y1:y2, x1:x2]\n",
    "                        if cropped_potato.size == 0: continue\n",
    "\n",
    "                        resized_crop = cv2.resize(cropped_potato, CLASSIFIER_IMG_SIZE)\n",
    "                        rgb_crop = cv2.cvtColor(resized_crop, cv2.COLOR_BGR2RGB)\n",
    "                        img_array = np.expand_dims(rgb_crop, axis=0)\n",
    "                        # preprocessed_img = preprocess_input(img_array)\n",
    "                        prediction_score = classifier_model.predict(img_array, verbose=0)[0][0]\n",
    "                        \n",
    "                        if prediction_score > 0.5:\n",
    "                            label = f\"Sprouted: {prediction_score:.2f}\"\n",
    "                            color = (0, 0, 255) # ç´…è‰²\n",
    "                        else:\n",
    "                            label = f\"Not Sprouted: {1-prediction_score:.2f}\"\n",
    "                            color = (0, 255, 0) # ç¶ è‰²\n",
    "                        \n",
    "                        latest_boxes_and_labels.append(((x1, y1, x2, y2), label, color))\n",
    "                \n",
    "                for box, label, color in latest_boxes_and_labels:\n",
    "                    (x1, y1, x2, y2) = box\n",
    "                    cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
    "                    cv2.putText(frame, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)\n",
    "                \n",
    "                cv2.imshow('Real-time Potato Sprout Detection', frame)\n",
    "                \n",
    "                frame_counter += 1\n",
    "\n",
    "                if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                    break\n",
    "\n",
    "            cap.release()\n",
    "            cv2.destroyAllWindows()\n",
    "            # åœ¨ Jupyter ä¸­ï¼Œæœ‰æ™‚éœ€è¦æ‰‹å‹•é—œé–‰æ‰€æœ‰è¦–çª—\n",
    "            for i in range(5):\n",
    "                cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee098b3-d711-4a05-90f8-3e03bece3bc4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
